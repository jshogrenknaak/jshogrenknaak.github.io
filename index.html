
<!DOCTYPE html>
<html lang="en">

<head>
    <title>Jasper Shogren-Knaak</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="author" content="Jasper Shogren-Knaak">
    <meta name="keywords" content="Jasper Shogren-Knaak, Jasper Shogren-Knaak nyu, Jasper Shogren-Knaak math, Jasper Shogren-Knaak Stanford, 刘丘雨">
    <meta name="robots" content="index,follow">
    <meta name="description" content="I am a graduate student in mathematics at the Courant Institute of Mathematical Sciences.">
    <link href="https://fonts.googleapis.com/css?family=Lato:100,300,400,700,900" rel="stylesheet">
  	<link rel="stylesheet" type="text/css" media="screen,print" href="css/style.css" />
	<link href="css/bootstrap.min.css" rel="stylesheet" media="screen" />
	<link rel="icon" type="image/png" href="images/CourantLogo.png">

</head>

<script>
function copy(dest, source) {
  if(dest.source == source) {
    dest.innerHTML = "";
    dest.source = null;
    dest.style.width="0px";
    dest.style.border = "";
    dest.style.padding = "0px";
    dest.style.margin = "0px";
  }
  else {
    dest.innerHTML = source.innerHTML;
    dest.source = source;
    dest.style.width = "800px";
    dest.style.padding = "10px";
    dest.style.border = "2px dotted gray";
    dest.style.background = "#F5F5F5";
    dest.style.margin = "10px";
  }
  dest.blur();
}
</script>

<body>
<div class="container">
<br>

<div class="row">
<div class="col-sm-5">
<a href="images/Untitled.png">
<img class="img-responsive" style="max-height:400px;" src="images/Untitled.png"/>
</a>
</div>

<div class="col-sm-7">
<div class="clearfix visible-xs-block"></div>
<h1>Jasper Shogren-Knaak<span style="font-family:STFangsong; font-size:20pt"> <!--<a href="chinese.html">(刘丘雨)</a>--></span></h1>


<!--
<div id="pronounceLink" style="display:block;"><p><a href="#" onclick="$('#pronounce').toggle(); return false;"><i>How to pronounce?</i></a></p></div>
<div id="pronounce" style="display:none;" class="alert">
	<p> My name can be pronounced as "Shwang - Ping - Lee":</p>
    <br>
        <audio controls="controls" controlslist="nodownload">
            <source src="audio/namestandard.m4a" type="audio/mpeg">
        </audio>
    <p> For a more advanced version, try this:</p>
    <br>
        <audio controls="controls" controlslist="nodownload">
            <source src="audio/nameadvanced.m4a" type="audio/mpeg">
        </audio>
</div>
-->


<a href="https://cims.nyu.edu/dynamic/">Courant Institute of Mathematical Sciences</a> <br>
<a href="https://www.nyu.edu">New York University</a>
<br>
<br>
<b>Email</b>: <tt>&#102;&#105;&#102;&#97;&#108;&#115;&#112;&commat;&#115;&#116;&#97;&#110;&#102;&#111;&#114;&#100;&period;&#101;&#100;&#117;</tt> <br>
<b>Address</b>: 
Sequoia Hall, 390 Jane Stanford Way, Stanford, CA 94305 USA<br>
<br>
</div>
<!-- <div class="col-sm-2">
<br><br><br>
<img class="img-responsive" style="max-height:300px;" src="images/seal.png" />
</div> -->
</div>
<br>


<p>
I am a Stein Fellow in the <a href="https://statistics.stanford.edu/">Department of Statistics</a> at Stanford University. I obtained my PhD degree in <a href="https://www.pacm.princeton.edu/">Applied and Computational Mathematics</a> from Princeton University in May 2022 under the supervision of Professor <a href="https://web.math.princeton.edu/~asly/">Allan Sly</a> and Professor <a href="https://web.math.princeton.edu/~eabbe/">Emmanuel Abbe</a>. Prior to Princeton, I received my Bachelor of Science in Mathematics from <a href="https://www.hku.hk/">University of Hong Kong</a>. My research focuses on probability theory and theoretical machine learning.
<br>
</p>

<hr>



<script>
        paper_count = 0

        function add_paper(title, authors, conference, link, bib, abstract, arxiv_link, journal_link, data, slides, talk, msg) {
            list_entry = "<li style=\"font-size:18px\">"
            if (link != null)
                list_entry += "<a href=\"" + link + "\">"
            list_entry += "<b>" + title + "</b>"
            if (link != null)
                list_entry += "</a>"
            list_entry += "<br>" + authors + ".<br>" + conference + ".</li>"

            if (bib != null) {
                list_entry += "<div id=\"bib" + paper_count + "\" style=\"display:none\">" + bib + "</div>"
                list_entry += "<a href=\"javascript:copy(div" + paper_count + ",bib" + paper_count + ")\"> <span class=\"label label-success\">bib</span></a>"
            }

            if (abstract != null) {
                list_entry += "<div id=\"abstract" + paper_count + "\" style=\"display:none\">" + abstract + "</div>"
                list_entry += "<a href=\"javascript:copy(div" + paper_count + ",abstract" + paper_count + ")\"> <span class=\"label label-mrdred\">abstract</span></a>"
            }
            if (arxiv_link != null)
                list_entry += " <a href=\"" + arxiv_link + "\"><span class=\"label label-mrdgreen\">arXiv</span></a>"

            if (journal_link != null)
                list_entry += " <a href=\"" + journal_link + "\"><span class=\"label label-mrdpurple\">journal</span></a>"

            if (data != null)
                list_entry += " <a href=\"" + data + "\"><span class=\"label label-default\">data</span></a>"

            if (slides != null)
                list_entry += " <a href=\"" + slides + "\"><span class=\"label label-info\">slides/poster</span></a>"

            if (talk != null)
                list_entry += " <a href=\"" + talk + "\"><span class=\"label label-mrdyellow\">video</span></a>"

            list_entry += "<br>"

            if (msg != null)
                list_entry += "<i>" + msg + "</i>"

            list_entry += "<div id=\"div" + paper_count + "\" style=\"font-size:15px\"></div><br>"

            document.write(list_entry)

            paper_count += 1
        }

        document.write("<h2>Research</h2>")
        document.write("<ul>")

        add_paper("Spectral clustering in the Gaussian mixture block model",
            "Joint work with Tselil Schramm",
            "arXiv: 2305.00979",
            "https://arxiv.org/abs/2305.00979",
            null,
            "Gaussian mixture block models are distributions over graphs that strive to model modern networks: to generate a graph from such a model, we associate each vertex with a latent feature vector sampled from a mixture of Gaussians, and we add edge if and only if the feature vectors are sufficiently similar. The different components of the Gaussian mixture represent the fact that there may be different types of nodes with different distributions over features---for example, in a social network each component represents the different attributes of a distinct community. Natural algorithmic tasks associated with these networks are embedding (recovering the latent feature vectors) and clustering (grouping nodes by their mixture component). In this paper we initiate the study of clustering and embedding graphs sampled from high-dimensional Gaussian mixture block models, where the dimension of the latent feature vectors goes to infinity as the size of the network goes to infinity. This high-dimensional setting is most appropriate in the context of modern networks, in which we think of the latent feature space as being high-dimensional. We analyze the performance of canonical spectral clustering and embedding algorithms for such graphs in the case of 2-component spherical Gaussian mixtures, and begin to sketch out the information-computation landscape for clustering and embedding in these models.",
            "https://arxiv.org/abs/2305.00979",
            null,
            null,
            null,
            null,
            null
        )

        add_paper("Binary perceptron: efficient algorithms can find solutions in a rare well-connected cluster",
            "Joint work with Emmanuel Abbe and Allan Sly",
            "STOC 2022",
            "https://arxiv.org/abs/2111.03084",
            null,
            "It was recently shown that almost all solutions in the symmetric binary perceptron are isolated, even at low constraint densities, suggesting that finding typical solutions is hard. In contrast, some algorithms have been shown empirically to succeed in finding solutions at low density. This phenomenon has been justified numerically by the existence of subdominant and dense connected regions of solutions, which are accessible by simple learning algorithms. In this paper, we establish formally such a phenomenon for both the symmetric and asymmetric binary perceptrons. We show that at low constraint density (equivalently for overparametrized perceptrons), there exists indeed a subdominant connected cluster of solutions with almost maximal diameter, and that an efficient multiscale majority algorithm can find solutions in such a cluster with high probability, settling in particular an open problem posed by Perkins-Xu '21. In addition, even close to the critical threshold, we show that there exist clusters of linear diameter for the symmetric perceptron, as well as for the asymmetric perceptron under additional assumptions.",
            "https://arxiv.org/abs/2111.03084",
            null,
            null,
            null,
            null,
            null
        )

        add_paper("Proof of the Contiguity Conjecture and Lognormal Limit for the Symmetric Perceptron",
            "Joint work with Emmanuel Abbe and Allan Sly",
            "FOCS 2021",
            "https://arxiv.org/abs/2102.13069",
            null,
            "We consider the symmetric binary perceptron model, a simple model of neural networks that has gathered significant attention in the statistical physics, information theory and probability theory communities, with recent connections made to the performance of learning algorithms in Baldassi et al. '15. We establish that the partition function of this model, normalized by its expected value, converges to a lognormal distribution. As a consequence, this allows us to establish several conjectures for this model: (i) it proves the contiguity conjecture of Aubin et al. '19 between the planted and unplanted models in the satisfiable regime; (ii) it establishes the sharp threshold conjecture; (iii) it proves the frozen 1-RSB conjecture in the symmetric case, conjectured first by Krauth-Mézard '89 in the asymmetric case. In a recent concurrent work of Perkins-Xu [PX21], the last two conjectures were also established by proving that the partition function concentrates on an exponential scale. This left open the contiguity conjecture and the lognormal limit characterization, which are established here. In particular, our proof technique relies on a dense counter-part of the small graph conditioning method, which was developed for sparse models in the celebrated work of Robinson and Wormald.",
            "https://arxiv.org/abs/2102.13069",
            null,
            null,
            null,
            "http://www.birs.ca/events/2021/5-day-workshops/21w5108/videos/watch/202108120814-Li.html?jwsource=cl",
            null
        )


        add_paper("Mean Field Behavior during the Big Bang for Coalescing Random Walk",
            "Joint work with Jonathan Hermon, Dong Yao, and Lingfu Zhang",
            "<i>Annals of Probability</i> (2022)",
            "https://arxiv.org/abs/2105.11585",
            null,
            "In this paper we consider the coalescing random walk model on general graphs G=(V,E). We set up a unified framework to study the leading order of decay rate  of P_t, the fraction of occupied sites at time t, and we are particularly interested in the `Big Bang' regime, where t << t_coal:=E[inf{s: there is only one particle at time s}]. Our results show that P_t satisfies certain `mean field behavior', if the graphs satisfy a certain `transience-like' condition. We apply this framework two families of graphs: (1) graphs given by configuration model with minimal degree at least 3, and (2) finite and infinite vertex-transitive graphs. In the first case, we show that for 1 << t << |V|, P_t decays in the order of t^{-1}, and tP_t is close to the probability that two particles starting from the root of the corresponding unimodular Galton-Watson tree never collide after one of them leaves the root. By taking the local weak limit, the convergence of tP_t is also proved for the corresponding unimodular Galton-Watson tree. For the second family of graphs, if we take a growing sequence of finite vertex-transitive graphs G_n=(V_n, E_n), such that the mean meeting time of two independent walkers t_meet is O(|V_n|) and the inverse of the spectral gap t_rel is o(|V_n|), we show for t_rel << t << t_coal, tP_t  = (1 + o(1))/P[two random walks never meet before time t]= 2t_meet/|V_n|. In addition, we define a certain natural `uniform transience' condition, and show that in the transitive setup it implies the above for all 1 << t << t_coal. The equality tP_t  = (1 + o(1))/P[two random walks never meet before time t] is also proved for all infinite transient transitive unimodular graphs, in particular, all transient  transitive amenable graphs.",
            "https://arxiv.org/abs/2105.11585",
            null,
            null,
            null,
            null,
            null
        )

        add_paper("Learning Sparse Graphons and the Generalized Kesten-Stigum Threshold",
            "Joint work with Emmanuel Abbe and Allan Sly",
            "<i>Annals of Statistics</i> (2023)",
            "https://arxiv.org/abs/2006.07695",
            null,
            "The problem of learning graphons has attracted considerable attention across several scientific communities, with significant progress over the recent years in sparser regimes. Yet, the current techniques still require diverging degrees in order to succeed with efficient algorithms in the challenging cases where the local structure of the graph is homogeneous. This paper provides an efficient algorithm to learn graphons in the constant expected degree regime. The algorithm is shown to succeed in estimating the rank-k projection of a graphon in the L2 metric if the top k eigenvalues of the graphon satisfy a generalized Kesten-Stigum condition.",
            "https://arxiv.org/abs/2006.07695",
            null,
            null,
            null,
            "https://www.youtube.com/watch?v=_QdrIQ5exF4",
            null
        )
        

        add_paper("A trace theorem for Sobolev spaces on the Sierpinski gasket",
            "Joint work with Shiping Cao, Robert S. Strichartz, and Prem Talwai",
            "<i>Commun. Pure Appl. Anal.</i> (2020)",
            "https://www.aimsciences.org/article/doi/10.3934/cpaa.2020159",
            null,
            "We give a discrete characterization of the trace of a class of Sobolev spaces on the Sierpinski gasket to the bottom line. This includes the L2 domain of the Laplacian as a special case. In addition, for Sobolev spaces of low orders, including the domain of the Dirichlet form, the trace spaces are Besov spaces on the line.",
            "https://arxiv.org/abs/1905.03391",
            "https://www.aimsciences.org/article/doi/10.3934/cpaa.2020159",
            null,
            null,
            null,
            null
        )

        add_paper("Computing Eigenvalues and Eigenfunctions of Schrödinger Equations Using a Model Reduction Approach",
            "Joint with Zhiwen Zhang",
            "<i>Commun. Comput. Phys.</i> (2018)",
            "https://global-sci.org/intro/article_detail/cicp/12319.html",
            null,
            "Let <i>F</i> be an NWUE distribution with mean 1 and <i>G</i> be the stationary renewal distribution of <i>F</i>. We would expect <i>G</i> to converge in distribution to the unit exponential distribution as its mean goes to 1. In this paper, we derive sharp bounds for the Kolmogorov distance between <i>G</i> and the unit exponential distribution, as well as between <i>G</i> and an exponential distribution with the same mean as <i>G</i>. We apply the bounds to geometric convolutions and to first passage times.",
            null,
            "https://global-sci.org/intro/article_detail/cicp/12319.html",
            null,
            null,
            null,
            null
        )

        document.write("</ul>")


        
</script>
<hr>

    <h2> Talks</h2>
    <ul>
        <li><a https://www.birs.ca/events/2024/5-day-workshops/24w5169>Frontiers of Statistical Mechanics and Theoretical Computer Science</a>, Aug, 2024, Banff.
        </li>
        <li><a href="https://www.kth.se/sn2024">Stochastic Networks 2024</a>, Jul, 2024, Stockholm.
        </li>
        <li><a href="https://icerm.brown.edu/events/htw-24-rma/#workshopoverview">Workshop on Random Matrices and Applications</a>, May, 2024, ICERM.
        </li>
        <li><a href="https://sites.gatech.edu/probschool2024/">Summer School 2024: Probability, Algorithms, and Inference</a>, May, 2024, Georgia Tech.
        </li>
        <li><a href="https://www.jointmathematicsmeetings.org/meetings/national/jmm2024/2300_program_ss78.html">Joint Mathematics Meetings</a>, Jan, 2024, San Francisco.
        </li>
        <li><a href="https://sites.google.com/view/la-probability-forum/home">LA Probability Forum</a>, Nov, 2023, Caltech.
        </li>
        <li><a href="https://sites.math.northwestern.edu/calendar/abstract.cgi?id=1692992531&dyear=2023">Northwestern University Probability Seminar</a>, Nov, 2023, Northwestern University.
        </li>
        <li><a href="https://www.stat.nus.edu.sg/2023/10/17/spectral-clustering-in-the-geometric-block-model/">NUS Joint Statistics, Data Science & Machine Learning Seminar</a>, Oct, 2023, Singapore.
        </li>
        <li><a href="https://statistics.stanford.edu/events/spectral-clustering-gaussian-mixture-block-model">Stanford University Probability Seminar</a>, Oct, 2023, Stanford University.
        </li>
        <li><a href="https://math.gatech.edu/seminars-colloquia/series/stochastics-seminar/shuangping-li-20230907">Georgia Tech Stochastics Seminar</a>, Sep, 2023, Georgia Tech.
        </li>
        <li><a href="https://newsen.pku.edu.cn/events/13184.html">Peking University Summer School on Probability</a>, Jun, 2023, Peking University.
        </li>
        <li><a href="https://mathematics.stanford.edu/events/spectral-clustering-geometric-block-model">Stanford University Applied Math Seminar</a>, May, 2023, Stanford University.
        </li>
        <li><a href="https://sites.google.com/view/stanfordwtf/home">Stanford University Women in Theory Forum</a>, Apr, 2023, Stanford University.
        </li>
        <li><a href="https://math.duke.edu/events/spectral-clustering-geometric-block-model">Duke University applied math and analysis seminar</a>, Apr, 2023, Duke University.
        </li>
        <li><a href="https://www.math.ucdavis.edu/research/seminars?talk_id=6722">UC Davis Probability Seminar</a>, Feb, 2023, UC Davis.
        </li>
        <li><a href="https://statistics.berkeley.edu/research/seminars/probability">UC Berkeley Probability Seminar</a>, Nov, 2022, UC Berkeley.
        </li>
        <li><a href="https://www.math.uci.edu/node/37526">UC Irvine Combinatorics and Probability Seminar</a>, Oct, 2022, UC Irvine.
        </li>
        <li><a href="https://statistics.stanford.edu/events/strong-freezing-binary-perceptron-model">Stanford University Probability Seminar</a>, Sep, 2022, Stanford University.
        </li>
        <li><a href="https://math.nyu.edu/dynamic/calendars/seminars/student-probability-seminar/">NYU Student Probability Seminar</a>, May, 2022, online.
        </li>
        <li><a href="https://hkumath.hku.hk/MathWWW/event/2022/NAS-LI_Shuangping.pdf">HKU Numerical Analysis Seminar</a>, May, 2022, online.
        </li>
        <li><t style="color:#428bca;">Penn Local Probability Seminar</t>, Apr, 2022, University of Pennsylvania.
        </li>
        <li><a href="https://www.jointmathematicsmeetings.org/meetings/national/jmm2022/2268_progfull.html">JMM 2022</a>, AAAS Special Session on Stochastic Processes on Networks, Apr, 2022, online.
        </li>
    	<li><a href="https://www.math.uic.edu/persisting_utilities/seminars/view_seminar?id=6875">UIC Probability and Combinatorics Seminar</a>, Mar, 2022, online.
        </li>
    	<li><a href="https://www.pacm.princeton.edu/events/pacm-colloquium-speakers-pacm-graduate-students-princeton-university">PACM Colloquium</a>, Feb, 2022, Princeton University.
        </li>
    	<li><a href="https://www.youtube.com/watch?v=HnNc9EOD8u4">2022 Symposium on Foundations of Computer Science</a>, Feb, 2022, online.
        </li>
        <li><a href="https://www.lehigh.edu/~sit218/Prob-2022s.html">LU-NU-UMN Joint Probability Seminar</a>, Feb, 2022, online.
        </li>
        <li><a href="https://statistics.stanford.edu/events/binary-perceptron">Stanford Statistics Seminar</a>, Feb, 2022, online.
        </li>
        <li><a href="https://www.pacm.princeton.edu/events/graduate-student-seminar-binary-perceptron-%C2%A0speaker-shuangping-li">PACM Graduate Student Seminar</a>, Jan, 2022, Princeton Univeristy.
        </li>
        <li><t style="color:#428bca;">Harvard Probabilitas Seminar</t>, Dec, 2021, online.
        </li>
        <li><a href="https://probability.commons.gc.cuny.edu/20th-northeast-probability-seminar/">Northeast Probability Seminar</a>, Nov, 2021, online.
        </li>
        <li><t style="color:#428bca;">MoDL Annual Meeting</t>, Oct, 2021, Simons Foundation in New York.
        </li>
    	<li><a href="http://www.birs.ca/events/2021/5-day-workshops/21w5108/videos/watch/202108120814-Li.html?jwsource=cl">Banff Workshop</a>, Random Graphs and Statistical Inference, Aug, 2021, online.
        </li>
        <li><a href="https://www.youtube.com/watch?v=2K4bYH6csA4&ab_channel=ColumbiaUniversity%2CProbability">Columbia-Princeton Probability Day</a>, May, 2021, online.
        </li>
        <li><a href="https://www.pacm.princeton.edu/events/online-seminar-graduate-student-seminar-proof-contiguity-conjecture-and-lognormal-limit">PACM Graduate Student Seminar</a>, Apr, 2021, online.
        </li>
        <li><t style="color:#428bca;">University of Basel Seminar in Probability Theory and Statistics</t>, Apr, 2021, online. 
        </li>
        <li><t style="color:#428bca;">MoDL Monthly Meeting</t>, Apr, 2021, online.
        </li>
        <li><a href="https://www.pacm.princeton.edu/events/online-seminar-graduate-student-seminar-learning-sparse-graphons-and-generalized-kesten">PACM Graduate Student Seminar</a>, Feb, 2021, online.
        </li>
        <li><a href="https://www.youtube.com/watch?v=_QdrIQ5exF4">Northeast Probability Seminar</a>, Nov, 2020, online.
        </li>
        <li><t style="color:#428bca;">PACM Graduate Student Seminar</t>, Nov, 2019, Princeton Univeristy.
        </li>
        <li><t style="color:#428bca;">Graduate Student Probability Seminar</t>, Oct, 2019, Duke University.
        </li>
        <li><t style="color:#428bca;">International Workshop on Inference on Graphical Models</t>, Oct, 2019, Columbia University.
        </li>
    </ul>


<hr>
    <h2>Teaching</h2>
    <ul>
        <span style="font-family: Lato; font-size:17px;">Instructor:</span>
        <li>STATS218 Introduction to Stochastic Processes II, Spring 2024.
        </li>
        <li>STATS317 Stochastic Processes, Winter 2024.
        </li>
        <li>STATS218 Introduction to Stochastic Processes II, Spring 2023.
        </li>
        <li>STATS116 Theory of Probability, Fall 2022.
        </li>
        <br>
        
        <span style="font-family: Lato; font-size:17px;">Assistant instructor:</span>
        <li>MAT100 Calculus Foundations, Fall 2020.
        </li>
        <li>MAT201 Multivariable Calculus, Fall 2019.
        </li>
        <li>MAT202 Linear Algebra with Applications, Spring 2019.
        </li>
    </ul>

<hr>

<h2>Services</h2>
<ul>
    <li><a href="https://statistics.stanford.edu/events/statistics-seminar">Stanford Statistics Seminar</a> (Organizer: Winter 2023, Winter 2024, Summer 2024).
    </li>
    <li><a href="https://statistics.stanford.edu/events/probability-seminar">Stanford Probability Seminar</a> (Organizer: Spring 2023).
    </li>
</ul>

<hr>


    <h2>Miscellaneous</h2>
<p>
I have a twin sister <a href="https://lsn235711.github.io/">Shuangning Li</a>. She graduated from Stanford University and is at Harvard University now. She works in statistics. Here is a <a href="https://lsn235711.github.io/misc.html">quiz</a> on my sister's website: Can you tell us apart?
</p>

<hr>
Last update: 2023/08. Template adapted from <a href="https://www.cs.princeton.edu/~danqic">Danqi Chen</a>'s.
<br>
<a href="chinese.html">中文版</a>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
</div>

<br>
<br>
</body>
</html>
